\documentclass[conference]{IEEEtran}

%\usepackage[russian]{babel}
\usepackage[justification=centering]{caption}
\usepackage[backend=bibtex]{biblatex}
\usepackage{fontspec}
\usepackage[final]{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{array}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
%\usepackage{geometry}
\graphicspath{{./images/}}

\setmainfont{Spectral Light}%{Times New Roman}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{white},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    morekeywords={*,procedure, if, rol, cmpj, setmask, then, else, endif, cmpjn, is, not, and, return},            % if you want to add more keywords to the set
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=10pt,
    xleftmargin=7mm,
    xrightmargin=0mm,
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}
\lstset{style=mystyle}
\lstset{linewidth=9cm}
\bibliography{syrcose} 


\begin{document}
\author{
    \IEEEauthorblockN{Nikita Nikiforov}
    \IEEEauthorblockA{\textit{Lomonosov Moscow State University}\\
    Moscow, Russia\\
    nickiforov.nik@gmail.com}
    \and
    \IEEEauthorblockN{Dmitry Volkanov}
    \IEEEauthorblockA{\textit{Lomonosov Moscow State University}\\
    Moscow, Russia\\
    volkanov@asvk.cs.msu.ru}
    }
\title{
    Data compression algorithms for flow tables in Network Processor (RuNPU).
}
\maketitle
    \begin{abstract}
        This paper addresses the problem of packet classification within a network processor (NP) architecture 
        without the separate associative device.
        By the classification, we mean the process of identifying a packet by the header.
        The classification stage requires the implementation of data structures to store the flow tables.
        In our work we consider NP without the associative memory. In considering NP flow tables
        represent like an assembly language program. For translating flow tables into assembly language programs,
        tables translator was used. 
        Nowadays flow tables can take tens of megabytes of memory.
        This is the reason for implement data compression algorithms in flow table translator.
        In this work we provide the data compression algorithms: Optimal rule caching, recursive end-point cutting and
        bit string compression. An evaluation of the implemented data compression algorithms was performed on a 
        simulation model of the NP.
    \end{abstract}
    
    \begin{IEEEkeywords}
        Network processor, software-defined networks, packet classification, data compression.
    \end{IEEEkeywords}

    \section{Introduction}
        At present, software-defined networks (SDN) are in active developing and require high-performance switches.
        The main functional element of the high-performance SDN switch is programmable network processor.
        The network processor is system-on-chip specialized for network packet processing. In our work we consider
        the programmable NP. By programmable we mean such NP, that supports to change the packet processing program 
        and the set of processed header fields on the fly. 
        
        This article will discuss about data compression algorithms used for flow tables. 
        Flow tables needs for packet classification process. Flow table is the set of flows, that defines
        by OpenFlow protocol. Each rule contains match field, bit string by witch a packet can be identified 
        and set of actions, that NP performs on this packet.
        The classification is the process of identification a network packet by it's header. 
        
    \section{Network processor architecture}
            \label{section:problem}
        In considered NP the pipeline architecture is used, each pipeline consists of 10 computing blocks. 
        To avoid complex organization of memory, there is no associative memory in the considered NP. 
        The NP uses the same memory for commands and data.
         
        Let consider the pipeline NP architecture. 
        Each computing block has access to the memory area where the program with data are located.
        There is a limit on the number of clock cycles that one packet can process on a processing block, 
        it corresponds to 25 clock cycles.
        All memory to store assembly language program that represents flow tables is 512 kilobytes.
        Due to the instruction set architecture, there is no separate memory area where data is stored. 
        Therefore, the microcode contains all the data, required to classify packets.
        \subsection{Flow tables translator}
            Flow table translator is a tool that performs on CPU. It used for flow table translating
            into assembly language program, that can by interprited by NP.
    \section{The problem}
    \label{sect:problem}
        Let consider OpenFlow tables formalisation. Ordered set of all considered attributes we'll denote as \(I=\{m_1,m_2,\ldots,m_k\}\). 
        Every attribute \(m_i\) from the set \(I\) described by bit string \(m_i \in \{0, 1, *\}^W_i\).
        In this article symbol \(*\) denote any bit. But, if \(\exists m_i^j \in m_i\) and  \( m_i^j = *\), 
        then for \( \forall m_i^k \), where \(k > j\), and \( m_i^k = *\). Length of the attribute will be \(len(m_i) = W_i\).

        Flow table will be represented as set of rules \(R=\{r_1,r_2,\ldots,r_n\}\). With every rule \(r_i\) bind the features:
        \begin{itemize}
            \item Index \(i\);
            \item Priority \(p_i \in \mathbb{Z}_+\);
            \item Vector values of the attributes \(f_i=\{f_i^1,f_i^2,\ldots,f_i^k\}\), there \(f_i^j\) is attribute value \(m_j\in I\). % Ð¸ \(f_i^j\in D(m_j)\cup\{*\}\), \(j=\overline{1,k}\).
            \item Set of actions \(A_i = \{a_1, a_2, \ldots, a_z\} \).
        \end{itemize}

        Network packet header \(x\) and its metadata with vector values of the attributes \(g=\{g^1,g^2,\ldots,g^k\}\) (\(x \rightarrow g\)),
        match rule \(r_i\in R\) with vector values of the attributes \(f_i=\{f_i^1,f_i^2,\ldots,f_i^k\}\) 
        and priority \(p_i\) (Rule \(r_i\in R\) identifies network packer with vector values of the attributes \(g\)), if:

        \begin{enumerate}
            \item vector values of the attributes \(g\) match vector values of the attributes \(f_i\), 
                \(\forall g_i \in g\), \(len(g_i) = len(f_i)\). \(\forall f_i^{lj} \in f_i^l\), \(f_i^{lj} \in \{*, g^{lj}\}\), \(l=\overline{1,k}\);
            \item the priority \(p_i\) is the highest among all rules \(r_j\in R\), witch vector \(g\) match vector\(f_j\).
        \end{enumerate}

        The set of rules \(R\) must satisfy the following constraint. 
        For any two rules \(r_i,r_j\in R,r_i\not= r_j\),  if their vectors of values intersect, there is a set of attribute values. 
        This set corresponds to vectors of values of attributes of both rules  \(p_i\not= p_j\). 
        
        Let's introduce the function for network packet identification \(x \rightarrow g\)in flow table \(R\), (will be note as \(R(x)\)).
        It will return a set of actions, that corresponds the rule \(x \rightarrow g\). 
        \begin{center}
            \(R(x) = A_{r_i}\), there \(A_{r_i}\) is the set of actions \(r_i \in R\).
        \end{center}

        We need introduce similar concept of the sets of rules \(R_1\) and \(R_2\).
        The set \(R_1\) is similar to the set \(R_2\), when for any network packet header, 
        that can be identified by some rule from the set \(r_i \in R_1\).
        And for this network packet header exist another rule that identifies it \(r_j \in R_2\), and \(A_i = A_j\).

        We need to develop algorithm for compressing flow tables. This algorithm must translate input flow table (the set of rules \(R_1\)
        into new compressed set of rules \(R_2\). 
        \begin{enumerate}
            \item The set of rules \(R_1\) is similar to the set of rules \(R_2\).
            \item Power of the set \(R_2\) must be lower than power of the set \(R_1\).
        \end{enumerate}

    \section{Related work}
        In this section we'll take a view on data compression algorithms, that already used
        for other network processors. We need to choose algorithms for use in our NP.
        For choosing algorithms we implemented criteria.
        \begin{enumerate}
            \item Compression rate, needs for algorithm performance evaluation.
            \item Evaluation of compression algorithm complexity.
            \item Usability compressed flow tables without decompression.
            \item The need to use external memory by the algorithm.
        \end{enumerate}

        \subsection{Most common data compression algorithms}
            Data compression algorithms have evolved over the years. Nowadays compression 
            algorithms can be used in many different ways. In this section we'll take a view
            on the algorithms that compressed data in binary format.
            There are most known of them:
            \begin{itemize}
                \item Huffman codding,
                \item JPEG,
                \item LWZ,
                \item zip.
            \end{itemize}
  
            These algorithms needs decompression for data usage. And this is why
            we'll not use them in our flow table translator.
        \subsection{Optimal rule caching}
            This is more specify data compressing algorithm. It used for table compressing in SND switches.
            It's based on search tree structure, that builds based on rules usage frequencies.
            There are two trees. The first tree - most usable rules. This tree translates into assembly
            language program. The second tree - another rules, it stores in CPU memory.
        \subsection{Recursive end point cutting}
            This algorithm based on HyperSplit tree usage. Compressing performs by destroying duplication rules~\cite{chang2019fast}.
            This algorithm allows operations with flow table without dull rebuilding tree.

            By rules duplication we'll understand next rules:
            \begin{itemize}
                \item The rule, that contains in node duplicates by rule in leaf node. (particle duplication).
                \item The rule, that contains in node duplicates by rules in all leafs nodes. (full duplicating rule).
            \end{itemize}
    \section{Our solution}
                ÐÐ²ÐµÐ´ÑÐ¼ Ð¾Ð¿ÐµÑÐ°ÑÐ¸Ñ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ð·Ð½Ð°ÑÐ°ÑÐµÐ³Ð¾ Ð±Ð¸ÑÐ° Ð¿ÑÐ¸Ð·Ð½Ð°ÐºÐ° \(last(m_i) = j\), ÑÐ°ÐºÐ¾Ðµ, ÑÑÐ¾ \(m_i^j \in \{0, 1\}\) Ð¸ \(m_i^{(j+1)} = *\). 
        ÐÐ°Ð·Ð¾Ð²ÑÐ¼ Ð¿ÑÐ°Ð²Ð¸Ð»Ð° \(r_i \in R\) Ð¸ \(r_j \in R\) Ð¿Ð¾ÑÐ¾Ð¶Ð¸Ð¼Ð¸, 
        ÐµÑÐ»Ð¸ Ð´Ð»Ñ \(\forall u \in len(f_i)\) Ð²ÐµÑÐ½Ð¾, ÑÑÐ¾ \(last(f_i^u) = last(f_j^u) = l\), Ð¿ÑÐ¸ ÑÑÐ¾Ð¼ \(f_i^{ul} \neq f_j^{ul}\), Ð¸ \(A_i = A_j\).
        ÐÐ»Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð° Ð¿Ð¾ÑÑÐµÐ±ÑÐµÑÑÑ Ð²Ð²ÐµÑÑÐ¸ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸ÑÐµÐ»ÑÐ½ÑÐµ Ð¾Ð±Ð¾Ð·Ð½Ð°ÑÐµÐ½Ð¸Ñ. ÐÐ²ÐµÐ´ÑÐ¼ Ð¿Ð¾Ð½ÑÑÐ¸Ðµ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² Ð¿Ð°ÐºÐµÑÐ¾Ð² \(P\),
            Ð³Ð´Ðµ \(p_x\) Ð¾Ð±Ð¾Ð·Ð½Ð°ÑÐ°ÐµÑ Ð²ÐµÑÐ¾ÑÑÐ½Ð¾ÑÑÑ Ð¿Ð¾Ð»ÑÑÐµÐ½Ð¸Ñ Ð¿Ð°ÐºÐµÑÐ° \(x \rightarrow g=\{g^1,g^2,\ldots,g^k\}\).
            Ð¢Ð°ÐºÐ¶Ðµ Ð²Ð²ÐµÐ´ÑÐ¼ Ð¿Ð¾Ð½ÑÑÐ¸Ðµ ÐºÐ¾ÑÑÑÐ¸ÑÐ¸ÐµÐ½ÑÐ° Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾ÑÑÐ¸ \(T_P(R_1, R_2)\), Ð³Ð´Ðµ \(R_1\) Ð¸ \(R_2\) Ð´Ð²Ðµ ÑÐ°Ð·Ð»Ð¸ÑÐ½ÑÐµ ÑÐ°Ð±Ð»Ð¸ÑÑ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð². 
            Ð¢Ð°ÐºÐ¸Ð¼ Ð¾Ð±ÑÐ°Ð·Ð¾Ð¼ ÐºÐ¾ÑÑÑÐ¸ÑÐ¸ÐµÐ½Ñ Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾ÑÑÐ¸ Ð¾Ð±Ð¾Ð·Ð½Ð°ÑÐ°ÐµÑ Ð²ÐµÑÐ¾ÑÑÐ½Ð¾ÑÑÑ ÑÐ¾Ð³Ð¾, ÑÑÐ¾ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð¿Ð°ÐºÐµÑÐ°, ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ \(P\),
            Ð±ÑÐ´ÐµÑ Ð² Ð¸Ð´ÐµÐ½ÑÐ¸ÑÐ¸ÑÐ¸ÑÐ¾Ð²Ð°ÑÑÑÑ Ð¿ÑÐ°Ð²Ð¸Ð»Ð°Ð¼Ð¸ \(r_1 \in R_1\) Ð¸ \(r_2 \in R_2\) Ð¸ Ð¸Ñ Ð½Ð°Ð±Ð¾ÑÑ Ð´ÐµÐ¹ÑÑÐ²Ð¸Ð¹ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑÑ \(A_1 = A_2, A_1 \in r_1, A_2 \in r_2\).
            
            \[T_P(R_1, R_2) = \sum_{x \rightarrow g, R_1(x) = R_2(x)} p_x\]

            ÐÐ²ÐµÐ´ÑÐ¼ Ð¾Ð¿ÑÐ¸Ð¼Ð°Ð»ÑÐ½Ð¾Ðµ Ð·Ð½Ð°ÑÐµÐ½Ð¸Ðµ ÐºÐ¾ÑÑÑÐ¸ÑÐ¸ÐµÐ½ÑÐ° Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾ÑÑÐ¸ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð¹ ÑÐ°Ð±Ð»Ð¸ÑÑ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² \(R\), ÑÐ¸ÑÐ»Ð° Ð¿ÑÐ°Ð²Ð¸Ð» \(n\) Ð¸ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² \(P\).
            \[\zeta(n, R, P) = \max_{R_i, |R_i| <= n} T_P(R, R_i)\]
            
            Ð¢Ð°ÐºÐ¸Ð¼ Ð¾Ð±ÑÐ°Ð·Ð¾Ð¼ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ñ Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ Ð½Ð°Ð¹ÑÐ¸ Ð¸ Ð¿Ð¾ÑÑÑÐ¾Ð¸ÑÑ ÑÐ°Ð±Ð»Ð¸ÑÑ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² \(R_a\), Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½ÑÑ Ð½Ð° Ð´Ð°Ð½Ð½Ð¾Ð¹ ÑÐ°Ð±Ð»Ð¸ÑÐµ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² \(R\)
            Ñ Ð½Ð°Ð¸Ð¼ÐµÐ½ÑÑÐ¸Ð¼ ÐºÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾Ð¼ Ð¿ÑÐ°Ð²Ð¸Ð» \(n_0\) Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑÐ½ÑÐµ Ð¾Ð¿ÑÐ¸Ð¼Ð°Ð»ÑÐ½ÑÐ¼ ÐºÐ¾ÑÑÑÐ¸ÑÐ¸ÐµÐ½ÑÐ¾Ð¼ Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾ÑÑÐ¸ \(\zeta(n, R, P)\).
            ÐÑÑÑÑ \(p^i\) Ð¿Ð¾Ð¿ÑÐ»ÑÑÐ½Ð¾ÑÑÑ (Ð²ÐµÑÐ¾ÑÑÐ½Ð¾ÑÑÑ) Ð²ÑÐ±Ð¾ÑÐ° Ð¿ÑÐ°Ð²Ð¸Ð»Ð° \(r_i \in R\), Ð² ÑÐ¾Ð¾ÑÐ²ÐµÑÑÑÐ²Ð¸Ðµ Ñ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² \(P\). ÐÑÑÑÑ
            Ð¿ÑÐ°Ð²Ð¸Ð»Ð° Ð² ÑÐ°Ð±Ð»Ð¸ÑÐµ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² \(R\) ÑÐ°ÑÐ¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ñ Ð² Ð¿Ð¾ÑÑÐ´ÐºÐµ Ð½Ðµ Ð²Ð¾Ð·ÑÐ°ÑÑÐ°Ð½Ð¸Ñ Ð¸Ñ Ð¿Ð¾Ð¿ÑÐ»ÑÑÐ½Ð¾ÑÑÐ¸. Ð¢Ð¾Ð³Ð´Ð°:
            \[\zeta(n, R, P) \geq \sum_{i \in [1, n]} p^i + 1 - \sum_{i \in [1, n_0]} p^i \geq n/n_0\]


    \section{Evaluation}
            ÐÐ»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ Ð¿Ð°ÑÐ°Ð¼ÐµÑÑÐ¾Ð² Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÑ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼Ñ Ð½Ð° ÑÐ·ÑÐºÐµ Ð°ÑÑÐµÐ¼Ð±Ð»ÐµÑÐ°, Ð¿Ð¾Ð»ÑÑÐ°ÐµÐ¼ÑÑ Ð¿ÑÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸
            ÑÐ¸ÑÑÐµÐ¼Ñ ÑÑÐ°Ð½ÑÐ»ÑÑÐ¸Ð¸ Ñ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð°Ð¼Ð¸ ÑÐ¶Ð°ÑÐ¸Ñ Ð¸ Ð±ÐµÐ·. ÐÐ»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼Ñ, Ñ Ð¿Ð¾Ð¼Ð¾ÑÑÑ ÑÐ¼ÑÐ»ÑÑÐ¾ÑÐ° ÑÐµÑÐµÐ²Ð¾Ð³Ð¾ Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ½Ð¾Ð³Ð¾ ÑÑÑÑÐ¾Ð¹ÑÑÐ²Ð°,
            Ð±ÑÐ´ÑÑ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÑÑÑ ÑÐ»ÐµÐ´ÑÑÑÐ¸Ðµ Ð¿Ð°ÑÐ°Ð¼ÐµÑÑÑ:
            \begin{itemize}
                \item ÐÐ±ÑÑÐ¼ Ð¿Ð°Ð¼ÑÑÐ¸ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÐ¼Ð¾Ð¹ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼Ð¾Ð¹ Ð¿ÑÐ¸ Ð¾Ð±ÑÐ°Ð±Ð¾ÑÐºÐµ Ð¿Ð°ÐºÐµÑÐ¾Ð² Ð½Ð° ÑÐ¼ÑÐ»ÑÑÐ¾ÑÐµ ÑÐµÑÐµÐ²Ð¾Ð³Ð¾ Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ½Ð¾Ð³Ð¾ ÑÑÑÑÐ¾Ð¹ÑÑÐ²Ð°.
                \item Ð¡ÑÐµÐ´Ð½ÐµÐµ Ð²ÑÐµÐ¼Ñ Ð¾Ð±ÑÐ°Ð±Ð¾ÑÐºÐ¸ Ð¿Ð°ÐºÐµÑÐ° Ð² ÑÐ°ÐºÑÐ°Ñ ÑÐµÑÐµÐ²Ð¾Ð³Ð¾ Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ½Ð¾Ð³Ð¾ ÑÑÑÑÐ¾Ð¹ÑÑÐ²Ð°.
            \end{itemize}
            
            ÐÐ»Ñ Ð¿ÑÐ¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ ÑÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÐ°Ð»ÑÐ½Ð¾Ð³Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ, Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»ÑÐ½Ð¾ Ð²ÑÐ¿Ð¾Ð»Ð½ÑÑÑ ÑÐ»ÐµÐ´ÑÑÑÐ¸Ðµ Ð´ÐµÐ¹ÑÑÐ²Ð¸Ñ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð½Ð°Ð±Ð¾ÑÐ° Ð²ÑÐ¾Ð´Ð½ÑÑ Ð´Ð°Ð½Ð½ÑÑ:
            \begin{enumerate}
                \item ÐÑÐ±ÑÐ°ÑÑ ÑÐ°Ð±Ð»Ð¸ÑÑ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÐ°.
                \item ÐÑÐ¾Ð²ÐµÑÑÐ¸ ÑÑÐ°Ð½ÑÐ»ÑÑÐ¸Ñ Ð²ÑÐ±ÑÐ°Ð½Ð½Ð¾Ð¹ ÑÐ°Ð±Ð»Ð¸ÑÑ Ð¿Ð¾ÑÐ¾ÐºÐ¾Ð² Ð² Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼Ñ Ð½Ð° ÑÐ·ÑÐºÐµ Ð°ÑÑÐµÐ¼Ð±Ð»ÐµÑÐ°:
                    \subitem $-$ Ð±ÐµÐ· Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð¾Ð² ÑÐ¶Ð°ÑÐ¸Ñ, Ð¾Ð±ÑÑÐ½Ð¾Ðµ Ð´ÐµÑÐµÐ²Ð¾;
                    \subitem $-$ Ð±ÐµÐ· Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð¾Ð² ÑÐ¶Ð°ÑÐ¸Ñ, Ñ ÐÐÐ Ð´ÐµÑÐµÐ²Ð¾Ð¼;
                    \subitem $-$ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ ÑÐ°Ð·ÑÐ°Ð±Ð¾ÑÐ°Ð½Ð½ÑÑ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð¾Ð² ÑÐ¶Ð°ÑÐ¸Ñ.
                \item ÐÑÐ¾Ð²ÐµÑÑÐ¸ ÑÐ¼ÑÐ»ÑÑÐ¸Ñ ÑÐ°Ð±Ð¾ÑÑ ÑÐµÑÐµÐ²Ð¾Ð³Ð¾ Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ½Ð¾Ð³Ð¾ ÑÑÑÑÐ¾Ð¹ÑÑÐ²Ð° Ñ Ð¿Ð¾Ð»ÑÑÐµÐ½Ð½ÑÐ¼Ð¸ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼Ð°Ð¼Ð¸ Ð½Ð° ÑÐ·ÑÐºÐµ Ð°ÑÑÐµÐ¼Ð±Ð»ÐµÑÐ°.
                \item ÐÑÐ¾Ð²ÐµÑÑÐ¸ Ð¾ÑÐµÐ½ÐºÑ ÑÐµÐ·ÑÐ»ÑÑÐ°ÑÐ¾Ð² Ð¿Ð¾Ð»ÑÑÐµÐ½Ð½ÑÑ Ð² Ð´Ð°Ð½Ð½Ð¾Ð¼ ÑÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÐµ.
            \end{enumerate}

    \section{Future work}
 \printbibliography{}
\end{document}
